---
title: Duality I
author: Elsa Riachi
categories: [Notes]
tags: [optimization]
date: 2021-11-08
math: true
---

<div style="display:none">
In this post I present a brief overview of duality in optimization. 
</div>

### Introduction

Consider a constrained optimization problem:

$$
\begin{equation}
\min _{x \in \mathbb{R}^{n}} f(x) \quad \text { subject to }\left\{\begin{array}{ll}
c_{i}(x)=0, & i \in \mathcal{E} \\
c_{i}(x) \geq 0, & i \in \mathcal{I},
\end{array}\right.
\end{equation}
$$

In a previous [post]({% post_url 2021-07-26-Constrained-Optimization-the-KKT-conditions %}) on the KKT conditions, we looked at the Lagrangian formulation of constrained optimization problems. Specifically, at a local optimizer $$x^*$$, we have the following necessary conditions:

$$
\begin{equation}
\begin{aligned}
\nabla_{x} \mathcal{L}\left(x^{*}, \lambda^{*}\right) &=0, & & \\
c_{i}\left(x^{*}\right) &=0, & & \text { for all } i \in \mathcal{E} \\
c_{i}\left(x^{*}\right) & \geq 0, & & \text { for all } i \in \mathcal{I} \\
\lambda_{i}^{*} & \geq 0, & & \text { for all } i \in \mathcal{I} \\
\lambda_{i}^{*} c_{i}\left(x^{*}\right) &=0, & & \text { for all } i \in \mathcal{E} \cup \mathcal{I}
\end{aligned}
\end{equation}
$$

<!-- $$\nabla f(x) = \sum_{i \in \mathcal{I} \cup \mathcal{E}} \lambda_i \nabla c_i(x)$$, with $$\lambda_i \geq 0$$ for all $$i \in \mathcal{I} \cap \mathcal{A}$$. This means that (in theory) if we know the Lagrange multipliers $$\{\lambda_i\}_i$$ we know $$\nabla f(x)$$. From there we can construct the set $$\{x: \nabla f(x) = \sum_{i \in \mathcal{I} \cup \mathcal{E}} \lambda_i \nabla c_i(x)\}$$, to which a local optimizer must belong. -->

### The Dual Problem and Weak Duality
Consider $$L(x, \lambda) = f(x) - \sum_i \lambda_i c_i(x) - \sum_j \mu_j c_j(x)$$ for $$i \in \mathcal{I}$$ and $$j \in \mathcal{E}$$. Suppose that we restrict $$x$$ to the feasible set, and we restrict $$\lambda_i \geq 0$$. It is obvious that $$L(x, \lambda, \mu)  \leq f(x)$$. If in addition, $$(x, \lambda, \mu)$$ satisfies the complementarity conditions $$\lambda_i c_i(x) = 0$$, then $$L(x, \lambda, \mu) = f(x)$$. In summary:

For all feasible $$x$$ and $$\lambda \geq 0$$:

\begin{equation}
  L(x, \lambda, \mu) \leq f(x)
\end{equation}

With equality if $$\lambda_i c_i(x)=0$$ for all $$i \in \mathcal{I}$$.

It follows immediately that for all feasible $$x$$:

\begin{equation}
  g(\lambda, \mu) = \inf_x L(x, \lambda, \mu) \leq f(x) ,\ \forall \lambda \leq 0
\end{equation}

Naturally, if $$x^**$$ is a feasible minimizer of $$f(.)$$:

\begin{equation}
  g(\lambda, \mu) \leq f(x^*),\ \forall \lambda \leq 0
\end{equation}

This property is known as **Weak Duality**, and it states that $$g(\lambda, \mu)$$ is a lower bound for $$f(x)$$ for all feasible $$x$$, and by extension, it is a lower bound for the solution $$f(x^*)$$.  Note that $$g(\lambda, \mu)$$ can be a vacuous lower bound for some values of $$\lambda$$. For example if we have a linear constraint $$c^T x \geq 0$$ and a nonzero $$\lambda > 0$$, then $$g(\lambda, \mu) = -\infty$$.

Since $$g(\lambda, \mu)$$ is the infimum of a set of affine functions of $$\lambda, \mu$$, it is concave with respect to $$(\lambda, \mu)$$. Note that this is true regardless of whether or not $$f(x)$$ is convex.

If we are the optimistic type we might see that there is a possibility for us to solve the original problem by maximizing $$g(\lambda, \mu)$$ over $$\lambda \geq 0$$. To see why, recall that $$g(\lambda, \mu)$$ is a lower bound for our objective $$f(x)$$ for all feasible $$x$$, perhaps the largest value of $$g(\lambda, \mu)$$ at $$\lambda \geq 0$$ is equal to the smallest value of $$f(x)$$ at feasible $$x$$. Duality theory finds conditions under which this is the case. We refer to the original problem as the **primal problem** and the following problem as the **dual**:

$$
\begin{align}
\max_{\lambda, \mu} \inf_x L(x, \lambda, \mu) \\
\lambda \geq 0 \\
\end{align}
$$

Note that the dual problem does not explicitly restrict $$x$$ to the feasible set.
However, the solution $$(x', \lambda', \mu')$$ of the dual can never have infeasible $$x'$$. To see why, suppose that for some $$\lambda', \mu'$$, $$x'$$ is the minimizer of $$f(x) - \lambda' c_i(x) - \mu' c_j(x)$$ and it is infeasible.
If we assume that $$(x', \lambda', \mu')$$ is the solution of the dual, we should have $$\lambda', \mu'$$ as the maximizers of $$f(x') - \lambda c_i(x') -  \mu c_j(x')$$.

**Case 1: inequality constraint $$\mathbf{c_i(x) \geq 0}$$ is violated:**\
Since $$c_i(x') < 0$$, its corresponding multiplier $$\lambda$$ increases the outer maximization objective as it gets larger. \
We have that: \
 $$f(x') - (\lambda + \Delta) c_i(x') - \mu' c_j(x) > f(x') - \lambda c_i(x') - \mu' c_j(x)$$ for all $$\Delta > 0$$. \
 However as $$\lambda$$ gets larger, the solution of the inner minimization cannot remain infeasible, since as $$\lambda$$ grows we incur a larger penalty from $$-\lambda c_i(x)$$. We therefore have a contradiction.


**Case 2: equality constraint $$\mathbf{c_j(x) = 0}$$ is violated**\
Suppose without loss of generality $$c_j(x') > 0$$, its corresponding multiplier $$\mu$$ increases the outer maximization objective as its value tends to $$-\infty$$. \
We have that \
$$f(x') - \lambda' c_i(x') - (\mu + \Delta) c_j(x) > f(x') - \lambda' c_i(x') - \mu c_j(x)$$ for all $$\Delta < 0$$. \
However as $$-\mu$$ gets larger, the solution of the inner minimization cannot remain infeasible, since as $$-\mu$$ grows we incur a larger penalty from $$-\mu c_i(x)$$. We therefore have a contradiction.

We have effectively replaced the constraints on $$x$$ with a max-min problem.
Since the solution of the dual problem cannot be infeasible, this can make it a good alternative in cases where the primal problem is difficult to solve. In the next section we examine conditions under which the dual objective is not just a lower bound, but an equivalent objective to the primal problem.

### Strong Duality

We know that $$g(\lambda, \mu)$$ is a lower bound for $$f(x)$$ for all feasible $$x$$, for all $$\lambda \geq 0$$. And we know that if we maximize over $$\lambda, \mu$$ we can obtain the tightest lower bound. But can we obtain the solution of the
primal problem?

We first show that if $$f(.)$$ and $$\{c(.)\}$$ are convex, the solution of the primal is a solution of the dual. We then show that under stricter conditions, a solution of the dual is a solution of the primal.



## References
{% bibliography --file numerical_opt %}
